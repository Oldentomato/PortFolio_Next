---
title: Latent space 간단 정리
date: 2023-05-10
description: Auto Encoder에서 나온 용어의 의미
tag: [딥러닝]
---  

## Feature가 필요한 이유?  
머신러닝은 input data를 output data로 대응시키는 블랙박스 형태입니다.  
이 블랙박스는 input data의 함수이며 선형 또는 비선형의 형태를 가질 수 있습니다.  
우리는 train data를 사용해서 이 함수를 학습하지만 항상 잘 되는 것은 아닙니다.  
머신러닝의 성능은 데이터의 양과 질에 굉장히 의존적입니다. 가장 이상적인 입력 데이터는 부족하지도, 과하지도 않은 정확한 데이터만 갖는 것입니다.  
정확한 데이터를 모으기 위해서는 먼저 충분한 데이터를 모으고, 모은 데이터들 가운데 어떤 feature가 유용한지 아닌지 확인하는 과정을 거칩니다.  
Feature의 유용성을 확인하는 과정을 특징 선택(feature selection), 또는 특징 추출(feature extraction)이라고 합니다.  
이 과정은 보통 learning과정 전에 실행됩니다. 이 과정은 머신러닝 구조에서 가장 핵심적인 전처리 과정에 속합니다.  
  
## 차원 축소란?  
우리가 훈련에 필요한 충분한 고차원의 입력 값을 가지고 있다고 가정해 봅시다. 모든 개수의 feature가 필요하지 않을 수도 있고,  
가지고 있는 feature들 중 몇몇 개는 다른 특징들의 조합으로 표현 가능하므로 불핑요 할 수도 있습니다.  
따라서 관찰 대상들을 잘 설명할 수 있는 잠재 공간(latent space)은 실제 관찰 공간(observation space)보다 작을 수 있습니다.  
이렇게 관찰 공간 위의 샘플 기반으로 잠재 공간을 파악하는 것을 차원축소라고 합니다.  
차원 축소는 데이터의 압축, 잡음 제거 효과가 있지만, 가장 중요한 의의는 관측 데이터를 잘 설명할 수 있는 잠재공간을 찾는 것입니다.  
[latent space 참고](https://dev-hani.tistory.com/entry/Latent-space-간단-정리)  
