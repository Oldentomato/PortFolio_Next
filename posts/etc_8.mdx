---
title: tensor-serving 서버 구축
date: 2023-06-30
description: tensor-serving을 이용한 ai 서버구축
tag: [tensorflow, 도커, 서버, 파이썬]
---  

## Pytorch와 다른 점  
예전에 작성했던 pytorch 모델을 이용한 fastapi서버에서는 도커 컨테이너에서 모델을 가져오고 fastapi를 이용하여 restapi화 하여 제작했다.  
하지만 tensorflow에서는 tensor-serving이라는 컨테이너가 따로 존재하는데, pytorch와 다른 방식으로 만들어야했다.  
tensor-serving 외에도 nvidia에서 만든 triton을 이용하여 배포하는 방법도 있다.  
tensor-serving, fastapi 등 다른 것들보다 더 빠르고 확장성이 넓다는 장점이 있지만 방법에 대한 문서가 많지 않아서 다음에 다시 다루도록 하겠다.  
tensor-serving은 컨테이너가 자동으로 볼륨 디렉토리에 모델을 탐지하고 api화 시켜 localhost로 서비스가 시작된다.  
그러기에 다른 컨테이너에서 fastapi를 이용하여 이미지를 받고 정제한 뒤, tensor-serving 컨테이너로 데이터를 넘겨 결과값을 받아와야 한다.  

## Predict 코드  
다음은 tensor-serving 컨테이너로 이미지를 넘기기 전 이미지를 정제하고 보낸 뒤, 검증 결과를 처리하는 코드이다.  
```python
def TestModel(path):
    image = cv2.imread(path, cv2.IMREAD_UNCHANGED)
    image = cv2.resize(image, dsize=(256,256),interpolation=cv2.INTER_LINEAR)

    image = image / 255.0
    image_arr = np.array(image)
    image_arr = np.expand_dims(image_arr,axis=0)

    data = json.dumps({"signature_name":"serving_default","instances":image_arr.tolist()})

    headers = {"content-type": "application/json"}
    json_response = requests.post('http://localhost:8501/v1/models/model:predict', data=data, headers=headers)
    prediction = json.loads(json_response.text)

    try:
        predict_arr = np.array(prediction['predictions'])
    except: 
        return -1
    else:
        result = np.argmax(predict_arr[0])

    return category[result]
```
fastapi에서 이미지 경로를 받아와 주고 이미지를 정제해준다.  
그 뒤, json으로 tensor-serving컨테이너로 데이터를 넘겨주는데 경로는 v1은 버전명으로 실제 폴더명에서 숫자를 의미한다.(밑에서 다시 설명하겠다)  
그 뒤의 경로는 도커 볼륨경로를 써주고 마지막에 :predict를 써주면 된다.  
여기서 텐서플로우 모델은 h5모델이 아닌 saved_model 형식으로 되어있어야 한다.  
변환 방법은 아래와 같다.  
```python
import tensorflow as tf

model = tf.keras.models.load_model('/data/api/tensorflow/saved_model/1/model.h5')

model.save('/data/api/tensorflow/saved_model/1/model')
```


## 도커 설정  
도커 실행 명령어는 아래와 같다.  
```bash
docker run -it --rm -p 8501:8501 -v /mnt/d/yaming_dataset/Yaming_AI/api/tensorflow/saved_model:/models/model tensorflow/serving:2.3.0
```
볼륨 경로설정에서 : 왼쪽의 경로를 확인하면 .../saved_model 까지 되어있는데 실제 saved_model 경로 안에는 숫자로만 된 폴더가 있어야 한다(1이나 2 같은 정수)  
이 숫자는 모델의 버전을 뜻하게 되고 요청할 때 경로에서 v1, v2 등으로 해주면 된다.  
: 오른쪽은 요청 경로를 뜻한다. 실제로 요청 경로를 오른쪽에 쓴 것대로 해주면 된다.  
